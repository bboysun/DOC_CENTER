## 唠唠KAFKA

首先大家都说kafka是个侧重于大吞吐量的消息中间件，那我们就先说下，kafka到底做了什么，让人们认为它侧重于大吞吐量的消息中间件。

#### 大吞吐量

大吞吐量就是一次性吞，一次性吐大量的请求，比如我们producer生产者会一次性吞吐出大量的数据到broker上，kafka是通过batch.size和linger.ms这两个参数进行控制的；

kafka的producer在发送消息的时候，并不是直接将消息发送到broker中的，而是发送到本地的一个消息队列中，后台启动一个线程不停地轮询这个消息队列，直到消息队列中的数据达到batch.size的阈值后，才会一次性将这些消息批量的发送到broker中，这样避免了每次发送消息的网络请求的性能消耗。默认的是16k；

另外一个就是linger.ms配置，指的是producer生产者每两次发送消息到broker中的一个时间间隔，有点delay延迟发送的感觉，也就是每次会收集一段时间的消息，然后再批量发送；

这两种方案一定程度上提高了kafka的高吞吐量；

那么我们把这两个配置都设置了，怎么办？那就任意满足其中一个条件就发送批量消息到broker上。

聊完大吞吐量，接下来我们聊聊一些概念类的东西比如：group consumer如何。

#### group consumer、topic、partition、broker

我理解的消费组应该是同一个业务应用服务的不同实例。一个消费组需要订阅一个topic，topic是一个逻辑概念，一个topic指的就是相同类型消息的消息集合，那topic真正对应的物理存储方式就是partition分区，一般来说一个topic需要几个partition呢？

最好的是kafka集群有几个broker就设置几个partition，partition分区数和broker服务器的数量是一致的。producer生产者在生产消息的时候会根据不同的分发策略发送消息到这个topic下的不同partition上，默认的分发策略是，如果消息有key值存在就根据key对partition分区数量做hash运算，如果没有key值，则进行轮询，顺序发送消息；当然我们也可以自定义发送策略，通过实现partitioner接口进行扩展。

每个消息被添加到分区时，会通过offset保证消息在一个partition中的顺序，但是无法保证跨分区的顺序性。

一个消费组中的消费者就能够从不同的partition中进行消费消息，需要注意的是，一个消费者只能消费一个分区，那么不得不提消费者分区分配策略。

1. rangeAssignor：范围分区，挨着顺序一片片的分区
2. RoundRobinAssignor：轮询分区，一个接着一个分区
3. StrickyAssignor：粘性分区，看起来结果和轮询分区是差不多的，一个接着一个分区，但是在去除一个消费者时，其他消费者的分区不会再调整，只会将空闲的分区重新分配给剩下的消费者，保证了最小化的Rebalance的移动。

那么又有个问题了，consumer group和Rebalance动作都是有谁在触控控制的呢？

有一个coordinator 来处理的，每当有一个消费者join group时，coordinator就会去触发Rebalance动作对每个消费者进行重新分区分配。



**幂等性**我们已经有一篇文章说过的，这里就不再赘述了。

接下来我们再说说怎样保证数据不丢失，即**完整性**。

kafka的消费者会有这样的一个配置，不知道你有没有留心注意过，enable.auto.commit的配置，默认是true。也就是会自动提交offset给broker，那么在我们自动提交以后，服务器挂了怎么办，那么这条数据kafka认为消费者已经消费过了，应为offset已经提交了，而我们的系统后来挂了，这条消息没有真正的落地。糟糕，那可如何是好，这个时候，我们就要把这个enable.auto.commit关掉，我们通过自己的业务手动来提交offset，可以通过consumer.commitSync()来手动提交，就是当我们真正的把这条数据处理完成以后再向kafka broker 提交offset，表示我们已经消费过这条消息了。



前面我们也说了，每个partition都会有自己的副本，对消息做灾备，这个参数是**replication.factor**，表示每个topic的partition有几个副本，一般至少有两个。既然有了副本，那么自然就有了leader-follower的关系，那么我们的leader至少要保证一个follower跟自己有心跳检测，就是**min.insync.replicas**参数来控制的，保证leader挂了，至少有一个follower吧；

这样还不够。最重要的就是**acks**参数要配置为all，在producer生产者上要配置，也就是说只有当leader和follower之间都已经全部备份完成以后才认为写成功了。那么producer生产者真的写失败了怎么办？不着急，还有个参数配置。

**retries=Max**，意思是生产者producer如果写失败了，就要不停地重复去写，它怎么知道写失败呢，那就是ack反馈的咯。那么这个时候会不会造成幂等性问题，其实是有可能的，那就绕回去看kafka幂等性那篇文章咯。

哈哈，是不是发现这些文章前后都是有关联的。你中有我，我中有你的感觉~~

